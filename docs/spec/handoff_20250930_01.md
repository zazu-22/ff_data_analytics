# Handoff: Data Model v4.3 - Expanded Stats + Player Identity (2025-09-30)

## What We Accomplished

1. **Identified critical gaps in nflverse data integration:**

   - `ff_playerids` missing: Contains 19 fantasy platform ID mappings with `mfl_id` as canonical crosswalk ID
   - `snap_counts` missing: Snap participation data (offense, defense, ST) - 6 stat types
   - `ff_opportunity` missing: Expected stats, variances, team shares - 170+ columns, ~40 selected for integration

1. **Made two critical architectural decisions:**

   - **ADR-009**: Single consolidated `fact_player_stats` table for all NFL stats (base + snaps + opportunity)
     - Scale analysis: 12-15M rows over 5 years, well within DuckDB limits
     - Avoids fact-to-fact joins (Kimball anti-pattern)
     - Unified grain: player-game-stat
   - **ADR-010**: Use `mfl_id` as canonical `player_id` (not `gsis_id`)
     - Platform-agnostic identifier from nflverse
     - Maps to 19 fantasy platforms/stat providers
     - Separates canonical identity from provider-specific IDs

1. **Created comprehensive documentation:**

   - **ADR-009**: Single consolidated fact table decision with scale analysis, query patterns, alternatives
   - **ADR-010**: mfl_id player identity with 19 provider ID mappings, rationale, migration path
   - **v4.3 addendum**: Added to `refined_data_model_plan_v4.md` with complete schemas and SQL examples
   - Updated implementation checklist with detailed Phase 1 seed requirements
   - Updated nflverse registry with 3 new datasets (ff_playerids, snap_counts, ff_opportunity)

## Current State

**Status:** Ready to generate samples and create Phase 1 seeds

**Key Architectural Decisions Locked In:**

- **Canonical player identity**: `mfl_id` from `ff_playerids` dataset (NOT gsis_id)
- **Fact table strategy**: Single `fact_player_stats` with ~96 stat types (50 base + 6 snap + 40 opportunity)
- **Staging approach**: Three staging models feed single fact via UNION ALL
- **Provider ID mapping**: All staging models explicitly map provider ID → mfl_id via `dim_player_id_xref` crosswalk

**Implementation Phases:**

1. **Phase 1 (BLOCKER)**: Generate samples + create seeds

   - `ff_playerids` sample (CRITICAL - required for all other work)
   - `dim_player_id_xref` seed with ALL 19 provider IDs
   - Other dimension seeds: `dim_franchise`, `dim_scoring_rule`, `dim_pick`, `dim_asset`

1. **Phase 2**: Staging models + expanded fact table

   - New: `stg_nflverse__snap_counts.sql`, `stg_nflverse__ff_opportunity.sql`
   - Updated: `stg_nflverse__player_stats.sql` (add mfl_id crosswalk join)
   - Expand: `fact_player_stats` with UNION ALL from 3 sources

1. **Phase 3**: Analysis marts

   - Snap efficiency: yards per snap
   - Variance analysis: actual vs expected (built-in from ff_opportunity)
   - Opportunity metrics: team shares, air yards

## Critical Files Updated

### New Files Created

- `docs/adr/ADR-009-single-consolidated-fact-table-nfl-stats.md` - Fact table architecture decision
- `docs/adr/ADR-010-mfl-id-canonical-player-identity.md` - Player identity strategy

### Files Modified

- `docs/spec/refined_data_model_plan_v4.md` - Added Addendum v4.3 (pages of SQL + implementation guidance)
- `docs/spec/SPEC-1_v_2.2_implementation_checklist_v_1.md` - Updated Section 2 and Section 7 with v4.3 requirements
- `src/ingest/nflverse/registry.py` - Added 3 datasets: ff_playerids (TIER 1), snap_counts, ff_opportunity (TIER 2)
- `docs/adr/README.md` - Added ADR-009 and ADR-010 to index

## Next Steps (Priority Order)

### 1. IMMEDIATE BLOCKER - Generate ff_playerids Sample (Phase 1)

**Critical:** ALL Phase 2 work is blocked until this completes.

```bash
# Verify registry update
cat src/ingest/nflverse/registry.py | grep -A 5 "ff_playerids"

# Generate sample (should work now that registry is updated)
make samples-nflverse DATASETS=ff_playerids

# Verify output
ls -la samples/nflverse/ff_playerids/
cat samples/nflverse/ff_playerids/_meta.json

# Inspect schema
uv run python -c "
import polars as pl
df = pl.read_parquet('samples/nflverse/ff_playerids/ff_playerids.parquet')
print('Shape:', df.shape)
print('\\nAll ID columns:', [c for c in df.columns if 'id' in c.lower()])
print('\\nSample rows:')
print(df.select(['mfl_id', 'gsis_id', 'sleeper_id', 'espn_id', 'ktc_id', 'name', 'position']).head(5))
"
```

**Validation checklist:**

- ☐ Sample file exists: `samples/nflverse/ff_playerids/ff_playerids.parquet`
- ☐ Primary key `mfl_id` is present and non-null for most rows
- ☐ All 19 provider ID columns present (see ADR-010 for full list)
- ☐ `name` and `merge_name` columns present (for TRANSACTIONS fuzzy matching)
- ☐ Typical row count: ~15,000+ players (active + historical)

### 2. Create dim_player_id_xref Seed (Phase 1 - BLOCKER)

**Source:** `samples/nflverse/ff_playerids/`
**Output:** `dbt/ff_analytics/seeds/dim_player_id_xref.csv`

**Required columns (ALL 19 provider IDs + attributes):**

```csv
player_id (mfl_id - canonical),
mfl_id,
gsis_id,
sleeper_id,
espn_id,
yahoo_id,
pfr_id,
fantasypros_id,
pff_id,
cbs_id,
ktc_id,
sportradar_id,
fleaflicker_id,
rotowire_id,
rotoworld_id,
stats_id,
stats_global_id,
fantasy_data_id,
swish_id,
cfbref_id,
nfl_id,
name,
merge_name,
position,
team,
birthdate,
draft_year
```

**Implementation options:**

**Option A - Manual script:**

```python
# Generate seed from sample
import polars as pl

df = pl.read_parquet('samples/nflverse/ff_playerids/ff_playerids.parquet')

# Rename mfl_id to player_id for canonical column
seed = df.select([
    pl.col('mfl_id').alias('player_id'),  # Canonical ID
    pl.col('mfl_id'),  # Also keep as mfl_id for clarity
    # All 19 provider IDs
    'gsis_id', 'sleeper_id', 'espn_id', 'yahoo_id', 'pfr_id',
    'fantasypros_id', 'pff_id', 'cbs_id', 'ktc_id', 'sportradar_id',
    'fleaflicker_id', 'rotowire_id', 'rotoworld_id', 'stats_id',
    'stats_global_id', 'fantasy_data_id', 'swish_id', 'cfbref_id', 'nfl_id',
    # Name matching + attributes
    'name', 'merge_name', 'position', 'team', 'birthdate', 'draft_year'
])

# Write to CSV
seed.write_csv('dbt/ff_analytics/seeds/dim_player_id_xref.csv')
print(f"Created seed with {len(seed)} rows")
```

**Option B - Create `tools/generate_seed_from_sample.py`:**

- Reusable script for generating seeds from sample data
- Could be used for other seeds (dim_pick, stat_dictionary, etc.)

**Validation:**

- ☐ Primary key `player_id` is unique (no duplicates)
- ☐ File size reasonable (~2-3 MB for 15K players)
- ☐ All ID columns nullable (not all players have all IDs)
- ☐ `merge_name` populated for name-based matching

### 3. Generate Tier 2 Samples (Phase 1)

```bash
# Generate snap_counts and ff_opportunity samples
make samples-nflverse DATASETS=snap_counts,ff_opportunity

# Verify snap_counts
uv run python -c "
import polars as pl
df = pl.read_parquet('samples/nflverse/snap_counts/snap_counts.parquet')
print('Snap counts shape:', df.shape)
print('Columns:', df.columns)
print('Sample:', df.head(3))
"

# Verify ff_opportunity
uv run python -c "
import polars as pl
df = pl.read_parquet('samples/nflverse/ff_opportunity/ff_opportunity.parquet')
print('FF opportunity shape:', df.shape)
print('Key expected stats columns:', [c for c in df.columns if 'exp' in c][:10])
print('Variance columns:', [c for c in df.columns if 'diff' in c][:10])
"
```

**Expected outputs:**

- `samples/nflverse/snap_counts/snap_counts.parquet` (~50-100K rows for recent seasons)
- `samples/nflverse/ff_opportunity/ff_opportunity.parquet` (~30-50K rows, 170+ columns)

### 4. Create Remaining Seeds (Phase 1)

**From reference data in `docs/spec/league_config_data/`:**

#### a) dim_franchise.csv

**Source:** `franchises.json` + `sleeper_league_mapping.json` + `owner_to_franchise_mapping.json`
**Transform:** Flatten ownership history to SCD Type 2 rows

Example structure:

```csv
franchise_id,franchise_name,division,established_year,owner_id,owner_name,owner_valid_from,owner_valid_to,is_current_owner,sleeper_roster_id
F001,Franchise 001,Lauren Noble Division,2012,Jon,Jon,2012,2012,false,12
F001,Franchise 001,Lauren Noble Division,2012,Alec,Alec,2013,2024,false,12
F001,Franchise 001,Lauren Noble Division,2012,Jason,Jason,2025,9999,true,12
F002,Franchise 002,Skyline Chili Division,2012,Blaise,Blaise,2012,2013,false,11
...
```

#### b) dim_scoring_rule.csv

**Source:** `rules_constants.json` (scoring section)
**Transform:** Flatten to SCD Type 2 structure

Example structure:

```csv
rule_id,rule_name,stat_name,points_per_unit,valid_from,valid_to,is_current
1,Half-PPR,reception,0.5,2012-01-01,9999-12-31,true
2,Half-PPR,passing_yard,0.04,2012-01-01,9999-12-31,true
3,Half-PPR,passing_td,4.0,2012-01-01,9999-12-31,true
4,Half-PPR,rushing_yard,0.1,2012-01-01,9999-12-31,true
5,Half-PPR,idp_tackle,0.5,2012-01-01,9999-12-31,true
6,Half-PPR,idp_sack,1.5,2012-01-01,9999-12-31,true
...
```

#### c) dim_pick.csv

**Generate:** 5 rounds × 12 teams × multiple years

Example structure:

```csv
pick_id,season,round,overall_pick,round_slot
2024_1_1,2024,1,1,1
2024_1_2,2024,1,2,2
...
2024_5_12,2024,5,60,12
2025_1_1,2025,1,1,1
...
```

Generate for years 2024-2030 (covers future draft picks that can be traded).

#### d) dim_asset.csv

**Source:** Union of players (from dim_player_id_xref) + picks (from dim_pick)

Example structure:

```csv
asset_id,asset_type,player_id,pick_id,display_name
P_12345,player,12345,,Patrick Mahomes
P_67890,player,67890,,Justin Jefferson
D_2024_1_1,pick,,2024_1_1,2024 Round 1 Pick 1
D_2024_1_2,pick,,2024_1_2,2024 Round 1 Pick 2
...
```

#### e) stat_dictionary.csv

**Source:** nflreadr stat definitions (reference in data dictionaries)
**Purpose:** Map provider-specific stat names to canonical neutral names

Example structure:

```csv
provider,provider_stat_name,canonical_stat_name,stat_category,is_additive
nflverse,completions,pass_completions,passing,true
nflverse,passing_yards,pass_yards,passing,true
nflverse,receptions,receptions,receiving,true
nflverse,offense_snaps,offense_snaps,participation,true
nflverse,receptions_exp,receptions_expected,expected,true
...
```

#### f) dim_name_alias.csv

**Source:** Derived from dim_player_id_xref + manual additions for known aliases

Example structure:

```csv
player_id,alias_name,alias_type
12345,Pat Mahomes,nickname
12345,Patrick Mahomes II,full_name
67890,Justin Jefferson,primary
67890,JJ,nickname
...
```

**Post-seed cleanup:**

- ☐ Validate all seed CSVs load without errors: `dbt seed --select dim_*`
- ☐ Test primary key uniqueness
- ☐ **Remove `docs/spec/league_config_data/` directory** after seeds validated (reference data no longer needed)

### 5. Create Staging Models (Phase 2)

**After seeds complete**, implement staging models that use crosswalk:

#### a) stg_nflverse\_\_player_stats.sql (update existing)

```sql
-- Key change: add crosswalk join
LEFT JOIN {{ ref('dim_player_id_xref') }} xref
  ON w.player_id = xref.gsis_id  -- Explicit: gsis_id → mfl_id
SELECT
  COALESCE(xref.player_id, -1) AS player_id,  -- mfl_id (canonical)
  ...
```

#### b) stg_nflverse\_\_snap_counts.sql (NEW)

```sql
-- Map via pfr_id
LEFT JOIN {{ ref('dim_player_id_xref') }} xref
  ON s.pfr_player_id = xref.pfr_id  -- Explicit: pfr_id → mfl_id
```

See `refined_data_model_plan_v4.md` addendum v4.3 for complete SQL.

#### c) stg_nflverse\_\_ff_opportunity.sql (NEW)

```sql
-- Map via gsis_id
LEFT JOIN {{ ref('dim_player_id_xref') }} xref
  ON o.player_id = xref.gsis_id  -- ff_opportunity uses gsis_id
```

Select ~40 key columns from 170+ available (expected stats, variances, team shares).

### 6. Expand fact_player_stats (Phase 2)

Update `models/core/fact_player_stats.sql`:

```sql
-- Union all three sources
SELECT * FROM {{ ref('stg_nflverse__player_stats') }}  -- ~50 stat types
{% if is_incremental() %} WHERE ... {% endif %}

UNION ALL

SELECT * FROM {{ ref('stg_nflverse__snap_counts') }}  -- 6 stat types
{% if is_incremental() %} WHERE ... {% endif %}

UNION ALL

SELECT * FROM {{ ref('stg_nflverse__ff_opportunity') }}  -- ~40 stat types
{% if is_incremental() %} WHERE ... {% endif %}
```

**Testing:**

- ☐ Grain test: unique(player_id, game_id, stat_name, provider, measure_domain, stat_kind)
- ☐ FK test: player_id → dim_player_id_xref.player_id
- ☐ Enum test: stat_kind ∈ {actual}
- ☐ Row count validation: should be ~96 × (player-games) after all sources loaded

### 7. Create Analysis Marts (Phase 3)

**After fact table expanded:**

#### a) Snap efficiency mart

```sql
-- rushing yards per offensive snap
SELECT
  player_id,
  season,
  week,
  MAX(CASE WHEN stat_name = 'rushing_yards' THEN stat_value END) AS rushing_yards,
  MAX(CASE WHEN stat_name = 'offense_snaps' THEN stat_value END) AS offense_snaps,
  rushing_yards / NULLIF(offense_snaps, 0) AS yards_per_snap
FROM {{ ref('fact_player_stats') }}
GROUP BY player_id, season, week
```

#### b) Built-in variance mart

```sql
-- actual vs expected (no calculation needed - ff_opportunity provides diff columns)
SELECT
  player_id,
  season,
  SUM(CASE WHEN stat_name = 'receptions' THEN stat_value END) AS receptions_actual,
  SUM(CASE WHEN stat_name = 'receptions_exp' THEN stat_value END) AS receptions_expected,
  SUM(CASE WHEN stat_name = 'receptions_diff' THEN stat_value END) AS receptions_variance
FROM {{ ref('fact_player_stats') }}
GROUP BY player_id, season
```

## Key Context for Next Session

### Critical Dependencies

1. **ff_playerids is the BLOCKER**: Nothing in Phase 2+ can proceed without this dataset and the resulting `dim_player_id_xref` seed.

1. **All player references use mfl_id**: Every staging model that touches player data MUST join to `dim_player_id_xref` to map provider ID → mfl_id.

1. **Scale is validated**: 12-15M rows (5 years) is well within DuckDB's sweet spot. No performance concerns.

### Sample Data Status

**Generated (existing):**

- ✅ players, weekly, injuries, schedule, teams (from previous sessions)
- ✅ TRANSACTIONS tab (commissioner data; ~1,000 rows; not yet parsed)

**Needs generation (v4.3):**

- ❌ ff_playerids (CRITICAL BLOCKER)
- ❌ snap_counts
- ❌ ff_opportunity

### Reference Data Lifecycle

**Current state:**

- `docs/spec/league_config_data/` contains reference data from legacy codebase
- Use for seed generation ONLY
- **IMPORTANT:** Delete this directory after seeds are validated (no longer needed; prevents confusion)

### Architectural Decisions Locked

**Cannot change without significant rework:**

- ✅ mfl_id as canonical player_id (ADR-010)
- ✅ Single consolidated fact table (ADR-009)
- ✅ 19 provider IDs in crosswalk (future-proofing)
- ✅ Staging → fact via UNION ALL pattern

**Can still adjust:**

- Which ff_opportunity columns to include (currently ~40 selected from 170+)
- Stat naming conventions (suffix patterns like `_exp`, `_diff`)
- Mart designs (efficiency metrics, variance calculations)

### Testing Strategy

**Critical tests for Phase 1:**

- ☐ `dim_player_id_xref` primary key uniqueness (mfl_id)
- ☐ No nulls in mfl_id column
- ☐ Crosswalk coverage: % of nflverse players with mfl_id match

**Critical tests for Phase 2:**

- ☐ Staging models: unmapped player_id = -1 count (should be minimal)
- ☐ `fact_player_stats` grain test passes
- ☐ Row count matches expected: ~96 stats × player-games
- ☐ Partition sizes reasonable (~8-15 MB per season-week)

### Scale Monitoring

**Metrics to track:**

- Total rows in `fact_player_stats` (target: 12-15M for 5 years)
- Partition sizes (target: \<50 MB per partition)
- Storage size (target: 900 MB - 1.8 GB compressed)
- Query performance (target: \<1s for single player-week queries)

### FFanalytics Work (Parallel Track)

**Status:** Separate from v4.3 work; defined in v4.1 addendum.

**Dependencies:**

- Also blocked by `dim_player_id_xref` (needs name → mfl_id mapping)
- Uses separate `fact_player_projections` table (ADR-007)
- Can proceed in parallel with v4.3 after Phase 1 seeds complete

### Documentation References

**Must read before implementing:**

- `docs/adr/ADR-009-single-consolidated-fact-table-nfl-stats.md` - Fact table architecture
- `docs/adr/ADR-010-mfl-id-canonical-player-identity.md` - Player identity strategy
- `docs/spec/refined_data_model_plan_v4.md` (addendum v4.3) - Complete SQL examples
- `docs/architecture/kimball_modeling_guidance/kimbal_modeling.md` - Dimensional modeling patterns

**Implementation checklist:**

- `docs/spec/SPEC-1_v_2.2_implementation_checklist_v_1.md` (Section 2, Section 7)

### Questions to Resolve

1. **Seed generation tool**: Should we create `tools/generate_seed_from_sample.py` for reusability, or use one-off scripts?

1. **ff_opportunity column selection**: Current plan selects ~40 from 170+ columns. Should we include more for future flexibility or keep minimal?

1. **Stat naming conventions**: Do we need a formal stat naming policy (e.g., suffix rules: `_exp` for expected, `_diff` for variance, `_pct` for percentages)?

1. **Historical data depth**: Current samples use recent seasons. For production, how many years back should we load? (5 years recommended based on scale analysis)

### Commit Strategy

**Suggested sequence:**

1. Commit registry updates (already done)
1. Generate samples → commit to samples/ (excluded from main repo via .gitignore, but good to track locally)
1. Create seeds → commit individually (each seed is independently useful)
1. Create staging models → commit as feature branch
1. Update fact table → commit with tests
1. Create marts → commit as analytics release

### Success Criteria

**Phase 1 complete when:**

- ✅ All 3 new datasets have sample data
- ✅ `dim_player_id_xref` seed exists with 19 provider IDs
- ✅ All other dimension seeds created and validated
- ✅ `dbt seed` runs without errors
- ✅ Primary key tests pass

**Phase 2 complete when:**

- ✅ 3 staging models created/updated
- ✅ `fact_player_stats` expanded with UNION ALL
- ✅ Grain test passes with ~96 stat types
- ✅ No unmapped players (or \<1% with player_id = -1)
- ✅ Row counts match expected scale

**Phase 3 complete when:**

- ✅ 2+ analysis marts demonstrate new capabilities
- ✅ Query examples from v4.3 addendum run successfully
- ✅ Documentation updated with actual performance metrics

### Known Risks

1. **ff_playerids coverage**: May not have 100% coverage for all nflverse players (historical players especially). Plan: use -1 as fallback player_id for unmapped players.

1. **ID mapping ambiguity**: Some players may have multiple IDs in same system (rare). Plan: trust nflverse crosswalk; log duplicates if found.

1. **Snap counts source**: Uses `pfr_player_id` not `gsis_id`. Plan: verified crosswalk has pfr_id column.

1. **ff_opportunity completeness**: Not all players have expected stats (backups, defensive players). Plan: accept nulls; sparsity handled by Parquet compression.

______________________________________________________________________

**Next developer**: Start with Step 1 (generate ff_playerids sample) and work sequentially through Phase 1. Do NOT proceed to Phase 2 until ALL seeds are validated. Reference ADR-009 and ADR-010 for architectural context.

**Questions?** Check `#ask-claude` in team chat or review the updated Kimball guidance doc.
