# Multi-Source Snapshot Governance — Implementation Plan

**Version**: 2.0\
**Date**: 2025-11-07\
**Status**: Active

______________________________________________________________________

This plan describes how we will stabilize snapshot handling across all 5 data sources (nflverse, sheets, ktc, ffanalytics, sleeper) and prepare for cloud storage and Prefect orchestration.

## Objectives

1. **Parameterize snapshot selection** — Eliminate hardcoded dates in dbt staging models; implement flexible macro supporting baseline + latest strategies
2. **Centralize snapshot metadata** — Create registry seed tracking current/historical snapshots across all sources
3. **Guard sample artifacts** — Prevent accidental promotion of sample data into production snapshots via `_samples/` directory structure
4. **Prepare cloud-ready storage** — Document GCS layout, retention policies, and IAM requirements (blueprint only, no migration)
5. **Implement comprehensive orchestration** — Build Prefect flows for all 5 sources (Phases 1+2 scope) with governance integration

## Scope

### Data Sources (All 5)

- **nflverse**: weekly player stats, snap counts, fantasy opportunity, schedule, teams
- **sheets**: Commissioner roster/transactions/picks from Google Sheets
- **ktc**: Keep Trade Cut dynasty valuations (1QB default)
- **ffanalytics**: R-based fantasy projections
- **sleeper**: League platform data integration

### dbt Models

- `stg_nflverse__player_stats` — Currently hardcoded `dt IN ('2025-10-01', '2025-10-27')`
- `stg_nflverse__snap_counts` — Currently hardcoded `dt IN ('2025-10-01', '2025-10-28')`
- `stg_nflverse__ff_opportunity` — Already uses `latest_snapshot_only()` macro ✅

### Tooling

- **Extend**: `tools/analyze_snapshot_coverage.py` with row deltas, coverage gaps, mapping rates
- **Create**: `tools/validate_manifests.py` for registry-driven validation with CI integration
- **Implement**: 5 Prefect flows for all sources (local execution)

### Orchestration

- **Prefect Phases 1+2**: Complete ingestion automation for all 5 sources
- **Local flows only**: No cloud deployment or advanced monitoring (deferred to future phases)

## Design Decisions

### 1. Snapshot Selection Macro

Implement flexible `snapshot_selection_strategy` macro supporting three strategies:

```sql
-- dbt/ff_analytics/macros/snapshot_selection.sql
{% macro snapshot_selection_strategy(source_glob, strategy='latest_only', baseline_dt=none) %}
  {% if strategy == 'latest_only' %}
    -- Select only the most recent snapshot
    and {{ latest_snapshot_only(source_glob) }}
  {% elif strategy == 'baseline_plus_latest' %}
    -- Select baseline snapshot + latest (for historical continuity)
    and (dt = '{{ baseline_dt }}' or {{ latest_snapshot_only(source_glob) }})
  {% elif strategy == 'all' %}
    -- No filter (load all snapshots for backfills)
  {% endif %}
{% endmacro %}
```

**Usage in staging models**:

```sql
-- stg_nflverse__player_stats.sql
with source as (
  select * from read_parquet(
    '{{ env_var("RAW_NFLVERSE_WEEKLY_GLOB", "data/raw/nflverse/weekly/dt=*/*.parquet") }}'
  )
  where 1=1
    {{ snapshot_selection_strategy(
        env_var("RAW_NFLVERSE_WEEKLY_GLOB", "data/raw/nflverse/weekly/dt=*/*.parquet"),
        strategy='baseline_plus_latest',
        baseline_dt=var('NFLVERSE_BASELINE_DT', '2025-10-01')
    ) }}
)
```

**Benefits**:

- Eliminates hardcoded dates in SQL
- Supports multiple selection patterns via single interface
- Enables environment-specific configuration via dbt vars

### 2. Sample Guardrails

**Path structure**: `data/raw/<source>/_samples/<dataset>/dt=YYYY-MM-DD/`

**Implementation**:

- Relocate existing samples from `data/raw/<source>/<dataset>/dt=2024-01-01/` to `_samples/` subdirectories
- Extend `src/ingest/nflverse/shim.py` with `samples: bool=False` parameter routing outputs to `_samples/` when True
- dbt globs remain `data/raw/<source>/<dataset>/dt=*/*.parquet` (won't match `_samples` prefix)

**Benefits**:

- Physical separation prevents accidental dbt reads of sample data
- Consistent pattern across all sources
- Preserves dataset hierarchy for clarity

### 3. Snapshot Registry Seed

Create governance registry tracking snapshot lifecycle:

**File**: `dbt/ff_analytics/seeds/snapshot_registry.csv`

**Columns**:

- `source` — Data provider (nflverse, sheets, ktc, ffanalytics, sleeper)
- `dataset` — Specific dataset within source (weekly, snap_counts, etc.)
- `snapshot_date` — Partition date (dt value)
- `status` — Lifecycle stage (pending, current, historical, archived)
- `coverage_start_season` — Earliest season in snapshot
- `coverage_end_season` — Latest season in snapshot
- `row_count` — Total rows for validation
- `notes` — Freeform description

**Example entries**:

```csv
source,dataset,snapshot_date,status,coverage_start_season,coverage_end_season,row_count,notes
nflverse,weekly,2025-11-05,current,2020,2025,97302,Complete 2020-2025
nflverse,weekly,2025-10-27,historical,2020,2024,89145,Historical baseline
nflverse,snap_counts,2025-11-05,current,2020,2025,136974,Complete
ktc,players,2025-11-01,current,,,5234,Dynasty valuations 1QB
```

**Benefits**:

- Deterministic selection logic referencing single source of truth
- CI validation against expected snapshots
- Audit trail for snapshot promotion/retirement
- LLM-friendly documentation of available data

### 4. Validation Tooling

#### Extend `tools/analyze_snapshot_coverage.py`

**New capabilities**:

- **Row deltas**: Compare row counts across snapshots (current vs historical)
- **Season/week coverage gaps**: Identify missing weeks within expected season ranges
- **Player mapping rates**: Sample-join to `dim_player_id_xref` to report unmapped players by dataset/week

**Example output**:

```
Snapshot Coverage Analysis
=========================

NFLverse Weekly:
- 2025-10-27: 89,145 rows (2020-2024, 100% mapped)
- 2025-11-05: 97,302 rows (+8,157 delta, 2020-2025, 98.7% mapped)

Coverage Gaps:
- Week 10 missing for 2025 season (expected by 2025-11-12)
```

#### Create `tools/validate_manifests.py`

**New tool for registry-driven validation**:

- Cross-check snapshot registry expectations against actual `_meta.json` manifests
- Verify row counts match between manifest and Parquet files
- Detect season/week gaps based on registry coverage ranges
- CI integration: Exit code 1 if validation fails

**CI usage**:

```bash
# In .github/workflows/data-pipeline.yml
- name: Validate Snapshot Manifests
  run: uv run python tools/validate_manifests.py --sources nflverse sheets --fail-on-gaps
```

### 5. Freshness Tests (Tightened Thresholds)

Add dbt source freshness tests with `loaded_at_field: dt` and per-source thresholds reflecting update cadence:

| Source          | Warn After | Error After | Rationale                                          |
| --------------- | ---------- | ----------- | -------------------------------------------------- |
| **sheets**      | 1 day      | 7 days      | Daily roster/transaction updates expected          |
| **nflverse**    | 2 days     | 7 days      | Weekly in-season, updates within 2 days post-games |
| **ffanalytics** | 2 days     | 7 days      | Weekly projection updates during season            |
| **ktc**         | 5 days     | 14 days     | Less frequent market valuations updates            |
| **sleeper**     | 1 day      | 7 days      | Daily roster changes and league activity           |

**Implementation in source YAML**:

```yaml
# dbt/ff_analytics/models/sources/src_nflverse.yml
sources:
  - name: nflverse
    description: "NFLverse datasets via nflreadpy"
    freshness:
      warn_after: {count: 2, period: day}
      error_after: {count: 7, period: day}
    loaded_at_field: dt

    tables:
      - name: weekly
        identifier: "weekly/dt=*/*.parquet"
```

**Benefits**:

- Pre-dbt safety net catches stale data before model execution
- Different thresholds per source reflect realistic update expectations
- CI failures surface freshness issues immediately

### 6. Prefect Orchestration (All 5 Sources)

Implement Prefect Phases 1+2 flows for comprehensive ingestion automation:

**Flows to create**:

1. `src/flows/google_sheets_pipeline.py` — Commissioner sheets copy + parse
2. `src/flows/nfl_data_pipeline.py` — NFLverse weekly/snap_counts/ff_opportunity
3. `src/flows/ktc_pipeline.py` — KTC players/picks fetch + stage
4. `src/flows/ffanalytics_pipeline.py` — R runner + projections export
5. `src/flows/sleeper_pipeline.py` — League rosters + transactions sync

**Governance integration**:

- Snapshot currency checks (validate latest dt meets freshness thresholds)
- Anomaly detection (row count deltas exceeding expected ranges)
- Manifest validation (call `validate_manifests.py` as flow task)
- Notifications on failures (log/email/Slack depending on severity)

**Scope**:

- **In scope**: Flow definitions, local execution, basic error handling
- **Out of scope**: Cloud deployment, advanced monitoring, backfill orchestration (Prefect Phases 3-4)

## Phase Structure

### Phase 0: Kickoff & Decision Ratification

**Purpose**: Formalize scope, approve governance approach, define success criteria before implementation begins.

**Activities**:

1. Confirm Prefect orchestration scope: All 5 sources (Phases 1+2)
2. Approve snapshot registry seed creation and governance model
3. Define success metrics and acceptance criteria
4. Identify blockers: GCS auth status, Prefect Cloud access, environment setup

**Deliverables**:

- Scope confirmation documented
- Registry approach approved
- Success metrics agreed upon
- Blockers captured with mitigation plans

**Exit Criteria**: Team alignment on full scope and approach before Phase 1 begins.

______________________________________________________________________

### Phase 1: Foundation

**Purpose**: Implement core snapshot selection infrastructure and clean up legacy sample artifacts.

**Activities**:

1. **Implement `snapshot_selection_strategy` macro**

   - Create `dbt/ff_analytics/macros/snapshot_selection.sql`
   - Define three strategies: `latest_only`, `baseline_plus_latest`, `all`
   - Wire into existing `latest_snapshot_only()` helper

2. **Update NFLverse staging models**

   - `stg_nflverse__player_stats`: Replace `dt IN ('2025-10-01', '2025-10-27')` with macro call
   - `stg_nflverse__snap_counts`: Replace `dt IN ('2025-10-01', '2025-10-28')` with macro call
   - `stg_nflverse__ff_opportunity`: Verify existing macro usage still works ✅

3. **Relocate sample artifacts**

   - Move `data/raw/nflverse/weekly/dt=2024-01-01/` → `data/raw/nflverse/_samples/weekly/dt=2024-01-01/`
   - Move root-level CSV/Parquet samples to `_samples/` directories
   - Update test fixtures in `tests/test_nflverse_samples_pk.py`

4. **Profile query performance**

   - Run `EXPLAIN` on updated staging models
   - Measure UNION query performance (baseline + latest)
   - Document query times; consider materialization if >30s

5. **Preserve schema drift handling**

   - Verify `union_by_name=true` in models where schema can evolve
   - Monitor null rates by column after snapshot updates

**Deliverables**:

- `snapshot_selection_strategy` macro functional
- 3 NFLverse staging models updated and tested
- Samples relocated to `_samples/` directories
- Performance baseline documented

**Success Criteria**:

- All dbt models compile successfully
- Row counts match pre-change baseline (comparison test passes)
- No CI breakage from sample path updates

______________________________________________________________________

### Phase 2: Governance

**Purpose**: Establish snapshot registry and validation tooling providing pre-dbt governance layer.

**Activities**:

1. **Create snapshot registry seed**

   - File: `dbt/ff_analytics/seeds/snapshot_registry.csv`
   - Populate with current snapshots for all 5 sources
   - Document snapshot lifecycle states (pending, current, historical, archived)

2. **Extend `tools/analyze_snapshot_coverage.py`**

   - Add row delta reporting (current vs previous snapshot)
   - Add season/week coverage gap detection
   - Add player mapping rate checks (join to `dim_player_id_xref`)
   - Output format: JSON + human-readable summary

3. **Create `tools/validate_manifests.py`**

   - Registry-driven validation (expected snapshots vs actual)
   - Manifest vs Parquet row count verification
   - CI integration hooks (exit code 1 on validation failure)
   - Optional: Slack/email notifications on critical failures

4. **Add freshness tests (all 5 sources)**

   - **sheets**: `warn_after: {count: 1, period: day}`, `error_after: {count: 7, period: day}`
   - **nflverse**: `warn_after: {count: 2, period: day}`, `error_after: {count: 7, period: day}`
   - **ffanalytics**: `warn_after: {count: 2, period: day}`, `error_after: {count: 7, period: day}`
   - **ktc**: `warn_after: {count: 5, period: day}`, `error_after: {count: 14, period: day}`
   - **sleeper**: `warn_after: {count: 1, period: day}`, `error_after: {count: 7, period: day}`

**Deliverables**:

- Snapshot registry seed tracking all current/historical snapshots
- Extended coverage analysis tool with delta/gap/mapping checks
- New manifest validation tool with CI integration
- Freshness tests configured for all 5 sources

**Success Criteria**:

- Registry seed loads without errors
- Coverage tool detects known gaps (e.g., missing Week 10 for 2025)
- Manifest validation passes for all current snapshots
- Freshness tests pass for recently updated sources

______________________________________________________________________

### Phase 3: Documentation

**Purpose**: Update authoritative SPEC checklist and create current-state ops documentation for LLMs and contributors.

**Activities**:

1. **Update SPEC v2.3 checklist FIRST**

   - File: `docs/spec/SPEC-1_v_2.3_implementation_checklist_v_0.md`
   - Reflect current snapshot selection state (hardcoded dates → macro)
   - Document freshness test implementation
   - Note snapshot registry governance model
   - Link to new ops docs

2. **Create 6 ops docs** (current-state focus):

   a. `docs/ops/snapshot_management_current_state.md`

   - What snapshot selection logic exists per source?
   - Which models use hardcoded dates vs macros?
   - Where are samples stored?
   - Snapshot lifecycle policy

   b. `docs/ops/ingestion_triggers_current_state.md`

   - How do loads run today? (GH Actions schedules, manual make commands)
   - Trigger frequency per source
   - Credential storage and access patterns

   c. `docs/ops/data_freshness_current_state.md`

   - Freshness test thresholds per source
   - How to detect stale data (dbt source freshness command)
   - Expected update cadence per source
   - No alerts/monitoring yet (future work)

   d. `docs/ops/orchestration_architecture.md`

   - Current orchestration: Mix of GH Actions + manual commands
   - Prefect plan status: Phase 1+2 flows in progress
   - Local vs cloud execution state
   - Dependencies between ingestion jobs

   e. `docs/ops/ci_transition_plan.md`

   - GitHub Actions → Prefect migration strategy
   - Parallel run period (1-2 weeks)
   - Rollback procedures if Prefect fails
   - Cut-over validation criteria
   - Note: Planning only, execution deferred

   f. `docs/ops/cloud_storage_migration.md`

   - GCS bucket layout (raw/stage/mart/ops)
   - Retention policies (lifecycle.json explanation)
   - IAM requirements and service account setup
   - DuckDB GCS configuration
   - Migration checklist
   - Note: Blueprint only, no actual migration

3. **Update dbt staging model documentation**

   - Add comments explaining snapshot selection strategy in each model
   - Document baseline date choices and rationale

**Deliverables**:

- SPEC v2.3 checklist reflects current implementation state
- 6 ops docs provide LLM-friendly current-state reference
- dbt model docs explain snapshot governance approach

**Success Criteria**:

- SPEC checklist passes accuracy review (matches actual code state)
- Ops docs answer "how does X work today?" questions
- New contributors can understand snapshot governance from docs alone

______________________________________________________________________

### Phase 4: Orchestration

**Purpose**: Implement Prefect flows (Phases 1+2 scope) for all 5 sources with governance integration.

**Activities**:

1. **Create `src/flows/` directory structure**

   - Establish flow naming conventions
   - Define shared utilities (validation tasks, notification helpers)

2. **Implement 5 Prefect flows**:

   a. `google_sheets_pipeline.py`

   - Tasks: Copy sheets → Parse → Write Parquet → Manifest
   - Governance: Validate row counts, check for required columns

   b. `nfl_data_pipeline.py`

   - Tasks: Fetch nflverse data → Write Parquet → Manifest → Snapshot registry check
   - Governance: Freshness validation, row delta anomaly detection

   c. `ktc_pipeline.py`

   - Tasks: Fetch KTC API → Parse → Write Parquet → Manifest
   - Governance: Valuation range checks, player mapping validation

   d. `ffanalytics_pipeline.py`

   - Tasks: Run R projections → Export Parquet → Manifest
   - Governance: Projection reasonableness checks (min/max/sum validations)

   e. `sleeper_pipeline.py`

   - Tasks: Fetch league data → Parse rosters/transactions → Write Parquet → Manifest
   - Governance: Transaction date ordering, roster size validations

3. **Integrate snapshot governance**

   - Wire `validate_manifests.py` as Prefect task
   - Add snapshot currency checks (latest dt meets freshness)
   - Implement anomaly detection (row deltas exceeding thresholds)
   - Configure notifications (log warnings, fail on critical errors)

4. **Local testing with Prefect UI**

   - Run each flow locally with Prefect dev server
   - Validate task execution order and dependency handling
   - Test failure scenarios (API down, invalid data, etc.)

**Deliverables**:

- 5 working Prefect flows covering all data sources
- Governance tasks integrated into each flow
- Local execution validated with Prefect UI

**Success Criteria**:

- All flows execute successfully in local Prefect environment
- Governance tasks catch known issues (e.g., stale data, anomalies)
- Flow logs provide useful debugging information
- No regressions in data output quality vs manual runs

**Out of Scope** (Prefect Phases 3-4):

- Cloud deployment (Prefect Cloud or self-hosted server)
- Advanced monitoring dashboards
- Backfill orchestration for historical snapshots
- Automated retry strategies with exponential backoff
- Production scheduling and dependency management

______________________________________________________________________

### Phase 5: CI Planning

**Purpose**: Document transition strategy from GitHub Actions to Prefect with parallel run period and rollback plan.

**Activities**:

1. **Document parallel run strategy**

   - Week 1: Add Prefect flows, keep GH Actions running
   - Week 2: Run both systems, compare outputs (row counts, manifests, timing)
   - Week 3: Cut over to Prefect if validation passes
   - Week 4+: Monitor Prefect; keep GH Actions disabled but available

2. **Define rollback procedures**

   - If Prefect fails during parallel run: Re-enable GH Actions schedules, disable Prefect deployments
   - Validate data integrity after rollback (compare manifests)
   - Debug Prefect locally before retrying parallel run
   - Document failure scenarios and recovery steps

3. **Create cut-over validation criteria**

   - Row count parity (±1% acceptable for sampling variance)
   - Manifest lineage fields populated correctly
   - Query performance no worse than baseline (±10%)
   - No freshness test failures for 3+ consecutive days
   - Team approval after 1-2 week parallel run

4. **Add validation tools to GH Actions**

   - Integrate `validate_manifests.py` into existing workflows
   - Add freshness check step before dbt run
   - Establish baseline metrics for comparison with Prefect

5. **Document Prefect vs GH Actions comparison process**

   - Automated diff of output manifests
   - Row count comparison queries
   - Timing metrics collection
   - Decision framework for cut-over approval

**Deliverables**:

- Documented parallel run strategy with timeline
- Rollback procedures covering multiple failure scenarios
- Cut-over validation criteria with objective metrics
- Comparison process for output validation

**Success Criteria**:

- Clear decision tree for cut-over approval
- Rollback procedures tested (dry run)
- Team understands validation criteria

**Note**: Actual CI cut-over execution is out of scope. This phase delivers planning documentation only.

______________________________________________________________________

### Phase 6: Cloud Blueprint

**Purpose**: Document GCS migration strategy and requirements without implementing actual cloud transition.

**Activities**:

1. **Draft GCS bucket layout documentation**

   - Bucket structure: `gs://ff-analytics/{raw,stage,mart,ops}/`
   - Partition patterns: `<source>/<dataset>/dt=YYYY-MM-DD/`
   - Retention policies per layer (raw: 90 days, stage: 30 days, mart: 365 days)
   - Lifecycle rules (transition to Nearline/Coldline/Archive)

2. **Document retention and lifecycle policies**

   - Explain `config/gcs/lifecycle.json` rules
   - Retention periods per data layer
   - Archival strategy for historical snapshots
   - Cost optimization considerations

3. **Document IAM requirements**

   - Required GCS permissions: `storage.objects.create`, `storage.objects.get`, `storage.objects.list`
   - Service account creation steps
   - Key management and rotation policy
   - Local dev vs CI credential patterns

4. **Document service account setup**

   ```bash
   # Create service account
   gcloud iam service-accounts create ff-analytics-ingestion \
       --display-name="FF Analytics Ingestion"

   # Grant GCS permissions
   gcloud projects add-iam-policy-binding PROJECT_ID \
       --member="serviceAccount:ff-analytics-ingestion@PROJECT_ID.iam.gserviceaccount.com" \
       --role="roles/storage.objectAdmin"

   # Download key
   gcloud iam service-accounts keys create gcp-service-account-key.json \
       --iam-account=ff-analytics-ingestion@PROJECT_ID.iam.gserviceaccount.com
   ```

5. **Document DuckDB GCS configuration**

   ```sql
   INSTALL httpfs;
   LOAD httpfs;

   -- Configure GCS access
   SET gcs_access_key_id = '...';
   SET gcs_secret_access_key = '...';

   -- Test read
   SELECT * FROM read_parquet('gs://ff-analytics/raw/nflverse/weekly/dt=*/weekly.parquet')
   LIMIT 10;
   ```

6. **Create migration checklist**

   - Pre-migration validation (data integrity checks)
   - Bucket creation and permission setup
   - Initial data copy (rsync/gsutil strategy)
   - DuckDB connection testing
   - Prefect flow env var updates (`EXTERNAL_ROOT=gs://ff-analytics/raw`)
   - Validation of cloud reads (performance, correctness)
   - Rollback plan if migration issues arise

7. **Optional: Prototype `tools/sync_snapshots.py`**

   - Safe bidirectional sync (local ↔ GCS)
   - Exclude `_samples/` directories
   - No overwrite of populated partitions unless `--force`
   - Dry-run mode for testing

**Deliverables**:

- Comprehensive GCS migration documentation
- IAM setup guide with example commands
- Migration checklist with validation steps
- Optional sync utility for manual migration assist

**Success Criteria**:

- Documentation complete enough for team to execute migration independently
- IAM requirements clearly specified
- Rollback plan covers major failure scenarios

**Note**: This phase produces documentation only. Actual GCS migration execution is explicitly out of scope.

______________________________________________________________________

## Success Metrics

Implementation is considered complete when all of the following are achieved:

- [ ] **Zero hardcoded snapshot dates in staging models** — All 3 NFLverse models use `snapshot_selection_strategy` macro
- [ ] **Snapshot registry tracking current/historical snapshots** — Registry seed exists with entries for all 5 sources
- [ ] **Working Prefect flows for all 5 sources** — All flows execute successfully in local environment
- [ ] **Freshness tests providing pre-dbt safety net** — Tests configured for all 5 sources with appropriate thresholds
- [ ] **CI transition plan documented with rollback procedures** — Planning doc complete with validation criteria
- [ ] **Cloud migration blueprint complete** — GCS documentation ready for future migration execution

## Risks & Mitigations

| Risk                                                                           | Impact | Mitigation                                                                                                             |
| ------------------------------------------------------------------------------ | ------ | ---------------------------------------------------------------------------------------------------------------------- |
| **Schema drift** across snapshots breaks UNION queries                         | High   | Use `union_by_name=true`, monitor null rates by column, add schema compatibility tests                                 |
| **Breaking changes** from snapshot selection changes affect downstream queries | High   | Implement comparison tests validating row counts match baseline, audit notebooks for hardcoded dt filters              |
| **Performance degradation** from UNION queries (baseline + latest)             | Medium | Profile with EXPLAIN before/after, consider materialized views if query time >30s, document expected timing            |
| **Notebook compatibility** issues from snapshot changes                        | Medium | Audit Jupyter notebooks for hardcoded dt= filters, add deprecation warnings, encourage dbt refs over raw Parquet reads |
| **Partial/late snapshots** during weekly updates                               | Medium | Baseline+latest pattern provides continuity, freshness tests catch staleness early                                     |
| **Mapping gaps** for snap_counts (offensive linemen)                           | Low    | Report unmapped rates via coverage tool, add targeted alias updates if needed                                          |

## Out of Scope

The following items are explicitly deferred to future work:

- **Prefect Phases 3-4**: Backfill orchestration, advanced monitoring dashboards, cloud deployment
- **Actual cloud migration**: GCS bucket setup and data migration (blueprint only in Phase 6)
- **CI cut-over execution**: GitHub Actions → Prefect transition (planning only in Phase 5)
- **Full GitHub Actions replacement**: Keep GH Actions as backup/fallback initially
- **Advanced monitoring**: Alerting dashboards, anomaly detection beyond basic thresholds
- **Automated snapshot promotion**: Manual registry updates initially, automation later

## References

- `docs/spec/SPEC-1_v_2.3_implementation_checklist_v_0.md` — Authoritative implementation status
- `docs/spec/prefect_dbt_sources_migration_20251026.md` — Detailed Prefect implementation guide (1273 lines)
- `dbt/ff_analytics/macros/get_latest_snapshot.sql` — Existing snapshot helper macro
- `tools/analyze_snapshot_coverage.py` — Coverage analysis tool (to be extended)
- `docs/architecture/kimball_modeling_guidance/kimbal_modeling.md` — Dimensional modeling patterns
- `docs/dev/repo_conventions_and_structure.md` — Repo layout and naming conventions
